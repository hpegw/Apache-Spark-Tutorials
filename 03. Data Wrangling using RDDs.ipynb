{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Spark Image](https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Apache_Spark_logo.svg/1200px-Apache_Spark_logo.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling using RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting Spark Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The programming language Python is used for the implementation in this course - for this we use 'pyspark. (PySpark documentation https://spark.apache.org/docs/latest/api/python/)\n",
    "PySpark is an interface for Apache Spark in Python. It not only allows you to write Spark applications using Python APIs, but also provides the PySpark shell for interactively analyzing your data in a distributed environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/24 16:40:49 WARN Utils: Your hostname, Gerhards-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.178.62 instead (on interface en8)\n",
      "22/01/24 16:40:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/Cellar/apache-spark/3.2.0/libexec/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/24 16:40:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# ipmort libraries from pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "# set values for Spark configuration\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Data Analysis\")\n",
    "\n",
    "# get (if already running) or create a Spark Context\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('spark.master', 'local')\n",
      "('spark.rdd.compress', 'True')\n",
      "('spark.app.id', 'local-1643038851310')\n",
      "('spark.driver.host', '192.168.178.62')\n",
      "('spark.serializer.objectStreamReset', '100')\n",
      "('spark.app.startTime', '1643038849970')\n",
      "('spark.submit.pyFiles', '')\n",
      "('spark.executor.id', 'driver')\n",
      "('spark.submit.deployMode', 'client')\n",
      "('spark.driver.port', '60065')\n",
      "('spark.app.name', 'Data Analysis')\n",
      "('spark.ui.showConsoleProgress', 'true')\n"
     ]
    }
   ],
   "source": [
    "# check (try) if Spark context variable (sc) exists and print information about the Spark context\n",
    "try:\n",
    "    sc\n",
    "except NameError:\n",
    "    print(\"Spark context does not context exist. Please create Spark context first (run cell above).\")\n",
    "else:\n",
    "    configurations = sc.getConf().getAll()\n",
    "    for item in configurations: print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.178.62:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Data Analysis</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=Data Analysis>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print link to Spark UI, Version, Master and AppName\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *For the Tutorials I will be using MovieLens 1M Dataset you can get it from the [Grouplens](https://grouplens.org/datasets/movielens/) website.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README       movies.dat   ratings.dat  users.dat\n"
     ]
    }
   ],
   "source": [
    "ls data/ml-1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "These files contain 1,000,209 anonymous ratings of approximately 3,900 movies \n",
      "made by 6,040 MovieLens users who joined MovieLens in 2000.\n",
      "\n",
      "USAGE LICENSE\n",
      "================================================================================\n",
      "\n",
      "Neither the University of Minnesota nor any of the researchers\n",
      "involved can guarantee the correctness of the data, its suitability\n",
      "for any particular purpose, or the validity of results based on the\n",
      "use of the data set.  The data set may be used for any research\n",
      "purposes under the following conditions:\n",
      "\n",
      "     * The user may not state or imply any endorsement from the\n",
      "       University of Minnesota or the GroupLens Research Group.\n",
      "\n",
      "     * The user must acknowledge the use of the data set in\n",
      "       publications resulting from the use of the data set\n",
      "       (see below for citation information).\n",
      "\n",
      "     * The user may not redistribute the data without separate\n",
      "       permission.\n",
      "\n",
      "     * The user may not use this information for any commercial or\n",
      "       revenue-bearing purposes without first obtaining permission\n",
      "       from a faculty member of the GroupLens Research Project at the\n",
      "       University of Minnesota.\n",
      "\n",
      "If you have any further questions or comments, please contact GroupLens\n",
      "<grouplens-info@cs.umn.edu>. \n",
      "\n",
      "CITATION\n",
      "================================================================================\n",
      "\n",
      "To acknowledge use of the dataset in publications, please cite the following\n",
      "paper:\n",
      "\n",
      "F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History\n",
      "and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4,\n",
      "Article 19 (December 2015), 19 pages. DOI=http://dx.doi.org/10.1145/2827872\n",
      "\n",
      "\n",
      "ACKNOWLEDGEMENTS\n",
      "================================================================================\n",
      "\n",
      "Thanks to Shyong Lam and Jon Herlocker for cleaning up and generating the data\n",
      "set.\n",
      "\n",
      "FURTHER INFORMATION ABOUT THE GROUPLENS RESEARCH PROJECT\n",
      "================================================================================\n",
      "\n",
      "The GroupLens Research Project is a research group in the Department of \n",
      "Computer Science and Engineering at the University of Minnesota. Members of \n",
      "the GroupLens Research Project are involved in many research projects related \n",
      "to the fields of information filtering, collaborative filtering, and \n",
      "recommender systems. The project is lead by professors John Riedl and Joseph \n",
      "Konstan. The project began to explore automated collaborative filtering in \n",
      "1992, but is most well known for its world wide trial of an automated \n",
      "collaborative filtering system for Usenet news in 1996. Since then the project \n",
      "has expanded its scope to research overall information filtering solutions, \n",
      "integrating in content-based methods as well as improving current collaborative \n",
      "filtering technology.\n",
      "\n",
      "Further information on the GroupLens Research project, including research \n",
      "publications, can be found at the following web site:\n",
      "        \n",
      "        http://www.grouplens.org/\n",
      "\n",
      "GroupLens Research currently operates a movie recommender based on \n",
      "collaborative filtering:\n",
      "\n",
      "        http://www.movielens.org/\n",
      "\n",
      "RATINGS FILE DESCRIPTION\n",
      "================================================================================\n",
      "\n",
      "All ratings are contained in the file \"ratings.dat\" and are in the\n",
      "following format:\n",
      "\n",
      "UserID::MovieID::Rating::Timestamp\n",
      "\n",
      "- UserIDs range between 1 and 6040 \n",
      "- MovieIDs range between 1 and 3952\n",
      "- Ratings are made on a 5-star scale (whole-star ratings only)\n",
      "- Timestamp is represented in seconds since the epoch as returned by time(2)\n",
      "- Each user has at least 20 ratings\n",
      "\n",
      "USERS FILE DESCRIPTION\n",
      "================================================================================\n",
      "\n",
      "User information is in the file \"users.dat\" and is in the following\n",
      "format:\n",
      "\n",
      "UserID::Gender::Age::Occupation::Zip-code\n",
      "\n",
      "All demographic information is provided voluntarily by the users and is\n",
      "not checked for accuracy.  Only users who have provided some demographic\n",
      "information are included in this data set.\n",
      "\n",
      "- Gender is denoted by a \"M\" for male and \"F\" for female\n",
      "- Age is chosen from the following ranges:\n",
      "\n",
      "\t*  1:  \"Under 18\"\n",
      "\t* 18:  \"18-24\"\n",
      "\t* 25:  \"25-34\"\n",
      "\t* 35:  \"35-44\"\n",
      "\t* 45:  \"45-49\"\n",
      "\t* 50:  \"50-55\"\n",
      "\t* 56:  \"56+\"\n",
      "\n",
      "- Occupation is chosen from the following choices:\n",
      "\n",
      "\t*  0:  \"other\" or not specified\n",
      "\t*  1:  \"academic/educator\"\n",
      "\t*  2:  \"artist\"\n",
      "\t*  3:  \"clerical/admin\"\n",
      "\t*  4:  \"college/grad student\"\n",
      "\t*  5:  \"customer service\"\n",
      "\t*  6:  \"doctor/health care\"\n",
      "\t*  7:  \"executive/managerial\"\n",
      "\t*  8:  \"farmer\"\n",
      "\t*  9:  \"homemaker\"\n",
      "\t* 10:  \"K-12 student\"\n",
      "\t* 11:  \"lawyer\"\n",
      "\t* 12:  \"programmer\"\n",
      "\t* 13:  \"retired\"\n",
      "\t* 14:  \"sales/marketing\"\n",
      "\t* 15:  \"scientist\"\n",
      "\t* 16:  \"self-employed\"\n",
      "\t* 17:  \"technician/engineer\"\n",
      "\t* 18:  \"tradesman/craftsman\"\n",
      "\t* 19:  \"unemployed\"\n",
      "\t* 20:  \"writer\"\n",
      "\n",
      "MOVIES FILE DESCRIPTION\n",
      "================================================================================\n",
      "\n",
      "Movie information is in the file \"movies.dat\" and is in the following\n",
      "format:\n",
      "\n",
      "MovieID::Title::Genres\n",
      "\n",
      "- Titles are identical to titles provided by the IMDB (including\n",
      "year of release)\n",
      "- Genres are pipe-separated and are selected from the following genres:\n",
      "\n",
      "\t* Action\n",
      "\t* Adventure\n",
      "\t* Animation\n",
      "\t* Children's\n",
      "\t* Comedy\n",
      "\t* Crime\n",
      "\t* Documentary\n",
      "\t* Drama\n",
      "\t* Fantasy\n",
      "\t* Film-Noir\n",
      "\t* Horror\n",
      "\t* Musical\n",
      "\t* Mystery\n",
      "\t* Romance\n",
      "\t* Sci-Fi\n",
      "\t* Thriller\n",
      "\t* War\n",
      "\t* Western\n",
      "\n",
      "- Some MovieIDs do not correspond to a movie due to accidental duplicate\n",
      "entries and/or test entries\n",
      "- Movies are mostly entered by hand, so errors and inconsistencies may exist\n"
     ]
    }
   ],
   "source": [
    "!cat data/ml-1m/README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Lets read in the ratings.dat nad create a ratings RDDs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " = sc.textFile(\"data/ml-1m/ratings.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1::1193::5::978300760',\n",
       " '1::661::3::978302109',\n",
       " '1::914::3::978301968',\n",
       " '1::3408::4::978300275',\n",
       " '1::2355::5::978824291']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Thats it We have read the Text file and we are printing out the first 5 rows using `take action` and make sure you don't use a collect action here because that will printout the whole RDD.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now if you check the readme file provided in the Dataset these are the columns in the Data*\n",
    "\n",
    ">*UserID::MovieID::Rating::Timestamp*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Lets check counts on each ratings given, But first we need to split our data and for that we need to make use of a Transformation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratingsRDD.map(lambda x: x.split('::')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', '3', '3', '4', '5']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ratings.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.defaultdict"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'5': 226310, '3': 261197, '4': 348971, '2': 107557, '1': 56174})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*So you can see how easy it was to get the ratings counter. As it has returned a dictionary lets sort and print the results.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings   Count\n",
      "\n",
      "★         56174\n",
      "★★        107557\n",
      "★★★       261197\n",
      "★★★★      348971\n",
      "★★★★★     226310\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "sortedResults = collections.OrderedDict(sorted(result.items()))\n",
    "print(f\"{'Ratings':10}{'Count'}\\n\")\n",
    "for key, value in sortedResults.items():\n",
    "    print(f\"{'★'* int(key):{10}}{value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Lets look at another example and check which are the most rated movies.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMovieNames():\n",
    "    movieNames = {}\n",
    "    with open(\"data/ml-1m/movies.dat\", encoding= 'ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            fields = line.split('::')\n",
    "            movieNames[int(fields[0])] = fields[1]\n",
    "    return movieNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameDict = sc.broadcast(loadMovieNames())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = ratingsRDD.map(lambda x: (int(x.split(\"::\")[1]), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1193, 1), (661, 1), (914, 1), (3408, 1), (2355, 1)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieCounts = movies.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1193, 1725), (661, 525), (914, 636), (3408, 1315), (2355, 1703)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieCounts.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = movieCounts.map( lambda x : (x[1], x[0]))\n",
    "sortedMovies = flipped.sortByKey(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3428, 2858), (2991, 260), (2990, 1196), (2883, 1210), (2672, 480)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedMovies.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedMoviesWithNames = sortedMovies.map(lambda countMovie : (nameDict.value[countMovie[1]], countMovie[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('American Beauty (1999)', 3428),\n",
       " ('Star Wars: Episode IV - A New Hope (1977)', 2991),\n",
       " ('Star Wars: Episode V - The Empire Strikes Back (1980)', 2990),\n",
       " ('Star Wars: Episode VI - Return of the Jedi (1983)', 2883),\n",
       " ('Jurassic Park (1993)', 2672),\n",
       " ('Saving Private Ryan (1998)', 2653),\n",
       " ('Terminator 2: Judgment Day (1991)', 2649),\n",
       " ('Matrix, The (1999)', 2590),\n",
       " ('Back to the Future (1985)', 2583),\n",
       " ('Silence of the Lambs, The (1991)', 2578)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedMoviesWithNames.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now these are top 10 most rated movies.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now lets look at movies with most 5 star ratings*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1::1193::5::978300760',\n",
       " '1::2355::5::978824291',\n",
       " '1::1287::5::978302039',\n",
       " '1::2804::5::978300719',\n",
       " '1::595::5::978824268']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_five_star(line):\n",
    "    splited_line= line.split(\"::\")\n",
    "    if splited_line[2] == '5':\n",
    "        return line\n",
    "five_start_rattingsRDD= ratingsRDD.filter(lambda x: filter_five_star(x))\n",
    "five_start_rattingsRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_start_movies = five_start_rattingsRDD.map(lambda x: (int(x.split(\"::\")[1]), 1))\n",
    "five_start_movieCounts = five_start_movies.reduceByKey(lambda x, y: x + y)\n",
    "flipped = five_start_movieCounts.map( lambda x : (x[1], x[0]))\n",
    "five_start_sortedMovies = flipped.sortByKey(ascending=False)\n",
    "five_start_sortedMoviesWithNames = five_start_sortedMovies.map(lambda countMovie : (nameDict.value[countMovie[1]], countMovie[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('American Beauty (1999)', 1963),\n",
       " ('Star Wars: Episode IV - A New Hope (1977)', 1826),\n",
       " ('Raiders of the Lost Ark (1981)', 1500),\n",
       " ('Star Wars: Episode V - The Empire Strikes Back (1980)', 1483),\n",
       " (\"Schindler's List (1993)\", 1475),\n",
       " ('Godfather, The (1972)', 1475),\n",
       " ('Shawshank Redemption, The (1994)', 1457),\n",
       " ('Matrix, The (1999)', 1430),\n",
       " ('Saving Private Ryan (1998)', 1405),\n",
       " ('Sixth Sense, The (1999)', 1385)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_start_sortedMoviesWithNames.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Lets look at number of movies produced in each year*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviesRDD =sc.textFile(\"data/ml-1m/movies.dat\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"1::Toy Story (1995)::Animation|Children's|Comedy\",\n",
       " \"2::Jumanji (1995)::Adventure|Children's|Fantasy\",\n",
       " '3::Grumpier Old Men (1995)::Comedy|Romance',\n",
       " '4::Waiting to Exhale (1995)::Comedy|Drama',\n",
       " '5::Father of the Bride Part II (1995)::Comedy']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moviesRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(1995)'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Toy Story (1995)'[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1995"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.search(r'\\([0-9]{4}\\)$','Grumpier Old Men (1995)').group(0)[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year(line):\n",
    "    split_line= line.split('::')\n",
    "    year= re.search(r'\\([0-9]{4}\\)$',split_line[1]).group(0)[1:-1]\n",
    "    return (year, 1)\n",
    "year_RDD= moviesRDD.map(lambda x: get_year(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1995', 1), ('1995', 1), ('1995', 1), ('1995', 1), ('1995', 1)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_RDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearCounts = year_RDD.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1995', 342), ('1994', 257), ('1996', 345), ('1976', 21), ('1993', 165)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yearCounts.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascending_sorted_yearCounts = yearCounts.sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1919', 3), ('1920', 2), ('1921', 1), ('1922', 2), ('1923', 3)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ascending_sorted_yearCounts.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "descending_sorted_yearCounts = yearCounts.sortByKey(ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2000', 156), ('1999', 283), ('1998', 337), ('1997', 315), ('1996', 345)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descending_sorted_yearCounts.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Years with most movies*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = yearCounts.map( lambda x : (x[1], x[0]))\n",
    "descending_sorted_yearCounts = flipped.sortByKey(ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(345, '1996'),\n",
       " (342, '1995'),\n",
       " (337, '1998'),\n",
       " (315, '1997'),\n",
       " (283, '1999'),\n",
       " (257, '1994'),\n",
       " (165, '1993'),\n",
       " (156, '2000'),\n",
       " (104, '1986'),\n",
       " (102, '1992')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descending_sorted_yearCounts.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Lets find out the which age group is most active on the platform*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1::1193::5::978300760',\n",
       " '1::661::3::978302109',\n",
       " '1::914::3::978301968',\n",
       " '1::3408::4::978300275',\n",
       " '1::2355::5::978824291']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_age_group():\n",
    "    age_group= {'1':  \"Under 18\", '18':  \"18-24\", '25':  \"25-34\", '35':  \"35-44\", '45':  \"45-49\", '50':  \"50-55\", '56':  \"56+\"}\n",
    "    user_ageGroup = {}\n",
    "    with open(\"data/ml-1m/users.dat\") as f:\n",
    "        for line in f:\n",
    "            fields = line.split('::')\n",
    "            user_ageGroup[int(fields[0])] = age_group[fields[2]]\n",
    "    return user_ageGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageGroupDict = sc.broadcast(load_age_group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ratings = ratingsRDD.map(lambda x: (int(x.split(\"::\")[0]), 1))\n",
    "count_user_ratings = users_ratings.reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 53), (2, 129), (3, 51), (4, 21), (5, 198)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_user_ratings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped = count_user_ratings.map( lambda x : (x[1], x[0]))\n",
    "age_group_count = flipped.map(lambda countuser : (ageGroupDict.value[countuser[1]], countuser[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group_counts= age_group_count.reduceByKey(lambda x , y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Under 18', 27211),\n",
       " ('56+', 38780),\n",
       " ('25-34', 395556),\n",
       " ('45-49', 83633),\n",
       " ('50-55', 72490),\n",
       " ('35-44', 199003),\n",
       " ('18-24', 183536)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_group_counts.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('25-34', 395556),\n",
       " ('35-44', 199003),\n",
       " ('18-24', 183536),\n",
       " ('45-49', 83633),\n",
       " ('50-55', 72490),\n",
       " ('56+', 38780),\n",
       " ('Under 18', 27211)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_group_counts.map(lambda x: (x[1], x[0])).sortByKey(ascending= False).map(lambda x: (x[1], x[0])).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Lets Load in another fake social network dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "friends = sc.textFile(\"data/fakefriends.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0,Will,33,385',\n",
       " '1,Jean-Luc,26,2',\n",
       " '2,Hugh,55,221',\n",
       " '3,Deanna,40,465',\n",
       " '4,Quark,68,21']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Lets look at the average number of friends broken down by age in this Dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseLine(line):\n",
    "    fields = line.split(',')\n",
    "    age = int(fields[2])\n",
    "    numFriends = int(fields[3])\n",
    "    return (age, numFriends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33, 385), (26, 2), (55, 221), (40, 465), (68, 21)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friendsRDD = friends.map(parseLine)\n",
    "friendsRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalsByAge = friendsRDD.mapValues(lambda x: (x, 1)).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33, (3904, 12)),\n",
       " (26, (4115, 17)),\n",
       " (55, (3842, 13)),\n",
       " (40, (4264, 17)),\n",
       " (68, (2696, 10))]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalsByAge.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "averagesByAge = totalsByAge.mapValues(lambda x: round(x[0] / x[1], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33, 325.33), (26, 242.06), (55, 295.54), (40, 250.82), (68, 269.6)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averagesByAge.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Lets load up another dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = sc.textFile(\"data/1800.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ITE00100554,18000101,TMAX,-75,,,E,',\n",
       " 'ITE00100554,18000101,TMIN,-148,,,E,',\n",
       " 'GM000010962,18000101,PRCP,0,,,E,',\n",
       " 'EZE00100082,18000101,TMAX,-86,,,E,',\n",
       " 'EZE00100082,18000101,TMIN,-135,,,E,']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Lets check the weather stations with minimum temperatures in 1800.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseLine(line):\n",
    "    fields = line.split(',')\n",
    "    stationID = fields[0]\n",
    "    entryType = fields[2]\n",
    "    temperature = float(fields[3]) * 0.1 * (9.0 / 5.0) + 32.0\n",
    "    return (stationID, entryType, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempRDD = temp.map(parseLine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ITE00100554', 'TMAX', 18.5),\n",
       " ('ITE00100554', 'TMIN', 5.359999999999999),\n",
       " ('GM000010962', 'PRCP', 32.0),\n",
       " ('EZE00100082', 'TMAX', 16.52),\n",
       " ('EZE00100082', 'TMIN', 7.699999999999999)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "minTemps = tempRDD.filter(lambda x: \"TMIN\" in x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ITE00100554', 'TMIN', 5.359999999999999),\n",
       " ('EZE00100082', 'TMIN', 7.699999999999999),\n",
       " ('ITE00100554', 'TMIN', 9.5),\n",
       " ('EZE00100082', 'TMIN', 8.599999999999998),\n",
       " ('ITE00100554', 'TMIN', 23.72)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minTemps.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationTemps = minTemps.map(lambda x: (x[0], x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "minTemps = stationTemps.reduceByKey(lambda x, y: round(min(x,y), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ITE00100554', 5.36), ('EZE00100082', 7.7)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minTemps.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Lets do another word count on a text file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = sc.textFile(\"data/Book.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Self-Employment: Building an Internet Business of One',\n",
       " 'Achieving Financial and Personal Freedom through a Lifestyle Technology Business']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeWords(text):\n",
    "    return re.compile(r'\\W+', re.UNICODE).split(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = book.flatMap(normalizeWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCounts = words.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('self', 111),\n",
       " ('employment', 75),\n",
       " ('building', 33),\n",
       " ('an', 178),\n",
       " ('internet', 26)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCounts.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCountsSorted = wordCounts.map(lambda x: (x[1], x[0])).sortByKey(ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1878, 'you'),\n",
       " (1828, 'to'),\n",
       " (1420, 'your'),\n",
       " (1292, 'the'),\n",
       " (1191, 'a'),\n",
       " (970, 'of'),\n",
       " (934, 'and'),\n",
       " (772, ''),\n",
       " (747, 'that'),\n",
       " (649, 'it')]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCountsSorted.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
